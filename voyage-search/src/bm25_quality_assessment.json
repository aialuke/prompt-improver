{
  "total_queries": 19,
  "query_results": [
    {
      "query": "calculate similarity",
      "type": "function_name",
      "results_count": 4,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333}, recall_at_k={1: 1.0, 3: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='calculate similarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', '\u0120similarity'], simple_tokens=['calculate', 'similarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenize text",
      "type": "function_name",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.5,
        0.5,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenize text', local_tokens=['tokenize', 'text'], voyage_tokens=['token', 'ize', '\u0120text'], simple_tokens=['tokenize', 'text'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "generate embeddings",
      "type": "function_name",
      "results_count": 3,
      "relevance_scores": [
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0}, recall_at_k={1: 0.0, 3: 0.0}, ndcg_at_k={1: 0.0, 3: 0.0}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='generate embeddings', local_tokens=['generate', 'embeddings'], voyage_tokens=['generate', '\u0120embeddings'], simple_tokens=['generate', 'embeddings'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "BM25Tokenizer",
      "type": "class_name",
      "results_count": 5,
      "relevance_scores": [
        1.0,
        1.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.6666666666666666, 5: 0.4}, recall_at_k={1: 0.5, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='BM25Tokenizer', local_tokens=['bm25tokenizer'], voyage_tokens=['BM', '2', '5', 'Tokenizer'], simple_tokens=['bm25tokenizer'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "HybridCodeSearch",
      "type": "class_name",
      "results_count": 7,
      "relevance_scores": [
        1.0,
        0.0,
        0.5,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(0.9502344167898356), 5: np.float64(0.9502344167898356)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='HybridCodeSearch', local_tokens=['hybrid', 'code', 'search'], voyage_tokens=['Hy', 'brid', 'Code', 'Search'], simple_tokens=['hybridcodesearch'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "TokenizationManager",
      "type": "class_name",
      "results_count": 5,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='TokenizationManager', local_tokens=['tokenization', 'manager'], voyage_tokens=['Token', 'ization', 'Manager'], simple_tokens=['tokenizationmanager'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "cosine similarity",
      "type": "method_call",
      "results_count": 7,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='cosine similarity', local_tokens=['cosine', 'similarity'], voyage_tokens=['cos', 'ine', '\u0120similarity'], simple_tokens=['cosine', 'similarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "stem words",
      "type": "method_call",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.5,
        0.5,
        0.5,
        0.5,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='stem words', local_tokens=['stem', 'words'], voyage_tokens=['stem', '\u0120words'], simple_tokens=['stem', 'words'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "remove stopwords",
      "type": "method_call",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='remove stopwords', local_tokens=['remove', 'stopwords'], voyage_tokens=['remove', '\u0120stopwords'], simple_tokens=['remove', 'stopwords'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "for loop iteration",
      "type": "code_pattern",
      "results_count": 6,
      "relevance_scores": [
        0.5,
        0.5,
        0.5,
        0.0,
        0.0,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(0.8318724637288826)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='for loop iteration', local_tokens=['loop', 'iteration'], voyage_tokens=['for', '\u0120loop', '\u0120iteration'], simple_tokens=['for', 'loop', 'iteration'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "try except error",
      "type": "code_pattern",
      "results_count": 6,
      "relevance_scores": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0}, ndcg_at_k={1: 0.0, 3: 0.0, 5: 0.0}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='try except error', local_tokens=['try', 'except', 'error'], voyage_tokens=['try', '\u0120except', '\u0120error'], simple_tokens=['try', 'except', 'error'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "import numpy",
      "type": "code_pattern",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='import numpy', local_tokens=['import', 'numpy'], voyage_tokens=['import', '\u0120numpy'], simple_tokens=['import', 'numpy'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "calculateSimilarity",
      "type": "camel_case",
      "results_count": 2,
      "relevance_scores": [
        1.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 1.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='calculateSimilarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', 'Similar', 'ity'], simple_tokens=['calculatesimilarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenizeText",
      "type": "camel_case",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.5,
        0.5,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenizeText', local_tokens=['tokenize', 'text'], voyage_tokens=['token', 'ize', 'Text'], simple_tokens=['tokenizetext'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "running",
      "type": "stemming_test",
      "results_count": 5,
      "relevance_scores": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0}, ndcg_at_k={1: 0.0, 3: 0.0, 5: 0.0}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='running', local_tokens=['running'], voyage_tokens=['running'], simple_tokens=['running'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenization",
      "type": "stemming_test",
      "results_count": 4,
      "relevance_scores": [
        1.0,
        1.0,
        0.5,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.6666666666666666}, recall_at_k={1: 0.5, 3: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenization', local_tokens=['tokenization'], voyage_tokens=['token', 'ization'], simple_tokens=['tokenization'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "similarities",
      "type": "stemming_test",
      "results_count": 6,
      "relevance_scores": [
        1.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.3333333333333333, 5: 0.2}, recall_at_k={1: 1.0, 3: 1.0, 5: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='similarities', local_tokens=['similarities'], voyage_tokens=['similar', 'ities'], simple_tokens=['similarities'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "the best algorithm for search",
      "type": "stopword_test",
      "results_count": 6,
      "relevance_scores": [
        0.5,
        0.5,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='the best algorithm for search', local_tokens=['best', 'algorithm', 'search'], voyage_tokens=['the', '\u0120best', '\u0120algorithm', '\u0120for', '\u0120search'], simple_tokens=['the', 'best', 'algorithm', 'for', 'search'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "a function to calculate",
      "type": "stopword_test",
      "results_count": 3,
      "relevance_scores": [
        0.5,
        0.0,
        0.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0}, recall_at_k={1: 0.0, 3: 0.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='a function to calculate', local_tokens=['function', 'calculate'], voyage_tokens=['a', '\u0120function', '\u0120to', '\u0120calculate'], simple_tokens=['a', 'function', 'to', 'calculate'], local_results=[], voyage_results=[], simple_results=[])"
    }
  ],
  "aggregate_metrics": {
    "avg_precision_at_5": 0.11578947368421054,
    "avg_recall_at_5": 0.5263157894736842,
    "avg_ndcg_at_5": 0.6201108884483536,
    "avg_mrr": 0.6842105263157895,
    "successful_queries": 19,
    "total_queries": 19
  },
  "tokenization_analysis": [
    "TokenizationComparison(query='calculate similarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', '\u0120similarity'], simple_tokens=['calculate', 'similarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenize text', local_tokens=['tokenize', 'text'], voyage_tokens=['token', 'ize', '\u0120text'], simple_tokens=['tokenize', 'text'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='generate embeddings', local_tokens=['generate', 'embeddings'], voyage_tokens=['generate', '\u0120embeddings'], simple_tokens=['generate', 'embeddings'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='BM25Tokenizer', local_tokens=['bm25tokenizer'], voyage_tokens=['BM', '2', '5', 'Tokenizer'], simple_tokens=['bm25tokenizer'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='HybridCodeSearch', local_tokens=['hybrid', 'code', 'search'], voyage_tokens=['Hy', 'brid', 'Code', 'Search'], simple_tokens=['hybridcodesearch'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='TokenizationManager', local_tokens=['tokenization', 'manager'], voyage_tokens=['Token', 'ization', 'Manager'], simple_tokens=['tokenizationmanager'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='cosine similarity', local_tokens=['cosine', 'similarity'], voyage_tokens=['cos', 'ine', '\u0120similarity'], simple_tokens=['cosine', 'similarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='stem words', local_tokens=['stem', 'words'], voyage_tokens=['stem', '\u0120words'], simple_tokens=['stem', 'words'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='remove stopwords', local_tokens=['remove', 'stopwords'], voyage_tokens=['remove', '\u0120stopwords'], simple_tokens=['remove', 'stopwords'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='for loop iteration', local_tokens=['loop', 'iteration'], voyage_tokens=['for', '\u0120loop', '\u0120iteration'], simple_tokens=['for', 'loop', 'iteration'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='try except error', local_tokens=['try', 'except', 'error'], voyage_tokens=['try', '\u0120except', '\u0120error'], simple_tokens=['try', 'except', 'error'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='import numpy', local_tokens=['import', 'numpy'], voyage_tokens=['import', '\u0120numpy'], simple_tokens=['import', 'numpy'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='calculateSimilarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', 'Similar', 'ity'], simple_tokens=['calculatesimilarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenizeText', local_tokens=['tokenize', 'text'], voyage_tokens=['token', 'ize', 'Text'], simple_tokens=['tokenizetext'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='running', local_tokens=['running'], voyage_tokens=['running'], simple_tokens=['running'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenization', local_tokens=['tokenization'], voyage_tokens=['token', 'ization'], simple_tokens=['tokenization'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='similarities', local_tokens=['similarities'], voyage_tokens=['similar', 'ities'], simple_tokens=['similarities'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='the best algorithm for search', local_tokens=['best', 'algorithm', 'search'], voyage_tokens=['the', '\u0120best', '\u0120algorithm', '\u0120for', '\u0120search'], simple_tokens=['the', 'best', 'algorithm', 'for', 'search'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='a function to calculate', local_tokens=['function', 'calculate'], voyage_tokens=['a', '\u0120function', '\u0120to', '\u0120calculate'], simple_tokens=['a', 'function', 'to', 'calculate'], local_results=[], voyage_results=[], simple_results=[])"
  ],
  "summary": {
    "overall_quality": "Good",
    "success_rate": 1.0,
    "key_findings": [
      "Low precision: Many irrelevant results in top positions"
    ]
  }
}