{
  "total_queries": 19,
  "query_results": [
    {
      "query": "calculate similarity",
      "type": "function_name",
      "results_count": 3,
      "relevance_scores": [
        1.0,
        1.0,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.6666666666666666}, recall_at_k={1: 0.5, 3: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='calculate similarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', 'similarity'], simple_tokens=['calculate', 'similarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenize text",
      "type": "function_name",
      "results_count": 6,
      "relevance_scores": [
        0.5,
        0.5,
        1.0,
        1.0,
        0.5,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.3333333333333333, 5: 0.4}, recall_at_k={1: 0.0, 3: 0.3333333333333333, 5: 0.6666666666666666}, ndcg_at_k={1: np.float64(0.5), 3: np.float64(0.617319681505689), 5: np.float64(0.7637012590219477)}, mrr=0.3333333333333333, total_relevant=3, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenize text', local_tokens=['tokenize', 'text'], voyage_tokens=['tokenize', 'text'], simple_tokens=['tokenize', 'text'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "generate embeddings",
      "type": "function_name",
      "results_count": 2,
      "relevance_scores": [
        0.5,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0}, recall_at_k={1: 0.0}, ndcg_at_k={1: np.float64(0.5)}, mrr=0.5, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='generate embeddings', local_tokens=['generate', 'embeddings'], voyage_tokens=['generate', 'embeddings'], simple_tokens=['generate', 'embeddings'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "BM25Tokenizer",
      "type": "class_name",
      "results_count": 0,
      "relevance_scores": [],
      "quality_metrics": "QualityMetrics(precision_at_k={}, recall_at_k={}, ndcg_at_k={}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='BM25Tokenizer', local_tokens=['bm25tokenizer'], voyage_tokens=['bm25tokenizer'], simple_tokens=['bm25tokenizer'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "HybridCodeSearch",
      "type": "class_name",
      "results_count": 10,
      "relevance_scores": [
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0, 10: 0.0}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0, 10: 0.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0), 10: np.float64(1.0)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='HybridCodeSearch', local_tokens=['hybrid', 'code', 'search'], voyage_tokens=['hybridcodesearch'], simple_tokens=['hybridcodesearch'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "TokenizationManager",
      "type": "class_name",
      "results_count": 2,
      "relevance_scores": [
        0.5,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0}, recall_at_k={1: 0.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='TokenizationManager', local_tokens=['tokenization', 'manager'], voyage_tokens=['tokenizationmanager'], simple_tokens=['tokenizationmanager'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "cosine similarity",
      "type": "method_call",
      "results_count": 1,
      "relevance_scores": [
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 1.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='cosine similarity', local_tokens=['cosine', 'similarity'], voyage_tokens=['cosine', 'similarity'], simple_tokens=['cosine', 'similarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "stem words",
      "type": "method_call",
      "results_count": 10,
      "relevance_scores": [
        1.0,
        1.0,
        1.0,
        1.0,
        0.5,
        0.5,
        0.5,
        0.5,
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 1.0, 5: 0.8, 10: 0.6}, recall_at_k={1: 0.16666666666666666, 3: 0.5, 5: 0.6666666666666666, 10: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(0.934397461243829), 10: np.float64(0.9805095853129349)}, mrr=1.0, total_relevant=6, total_queries=1)",
      "tokenization": "TokenizationComparison(query='stem words', local_tokens=['stem', 'words'], voyage_tokens=['stem', 'words'], simple_tokens=['stem', 'words'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "remove stopwords",
      "type": "method_call",
      "results_count": 2,
      "relevance_scores": [
        1.0,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 1.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='remove stopwords', local_tokens=['remove', 'stopwords'], voyage_tokens=['remove', 'stopwords'], simple_tokens=['remove', 'stopwords'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "for loop iteration",
      "type": "code_pattern",
      "results_count": 2,
      "relevance_scores": [
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 0.5}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='for loop iteration', local_tokens=['loop', 'iteration'], voyage_tokens=['for', 'loop', 'iteration'], simple_tokens=['for', 'loop', 'iteration'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "try except error",
      "type": "code_pattern",
      "results_count": 10,
      "relevance_scores": [
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 1.0, 5: 1.0, 10: 1.0}, recall_at_k={1: 0.1, 3: 0.3, 5: 0.5, 10: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0), 10: np.float64(1.0)}, mrr=1.0, total_relevant=10, total_queries=1)",
      "tokenization": "TokenizationComparison(query='try except error', local_tokens=['try', 'except', 'error'], voyage_tokens=['try', 'except', 'error'], simple_tokens=['try', 'except', 'error'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "import numpy",
      "type": "code_pattern",
      "results_count": 10,
      "relevance_scores": [
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 1.0, 5: 1.0, 10: 1.0}, recall_at_k={1: 0.1, 3: 0.3, 5: 0.5, 10: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0), 10: np.float64(1.0)}, mrr=1.0, total_relevant=10, total_queries=1)",
      "tokenization": "TokenizationComparison(query='import numpy', local_tokens=['import', 'numpy'], voyage_tokens=['import', 'numpy'], simple_tokens=['import', 'numpy'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "calculateSimilarity",
      "type": "camel_case",
      "results_count": 3,
      "relevance_scores": [
        1.0,
        1.0,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 0.6666666666666666}, recall_at_k={1: 0.5, 3: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='calculateSimilarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculatesimilarity'], simple_tokens=['calculatesimilarity'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenizeText",
      "type": "camel_case",
      "results_count": 6,
      "relevance_scores": [
        0.5,
        0.5,
        1.0,
        1.0,
        0.5,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.3333333333333333, 5: 0.4}, recall_at_k={1: 0.0, 3: 0.3333333333333333, 5: 0.6666666666666666}, ndcg_at_k={1: np.float64(0.5), 3: np.float64(0.617319681505689), 5: np.float64(0.7637012590219477)}, mrr=0.3333333333333333, total_relevant=3, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenizeText', local_tokens=['tokenize', 'text'], voyage_tokens=['tokenizetext'], simple_tokens=['tokenizetext'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "running",
      "type": "stemming_test",
      "results_count": 10,
      "relevance_scores": [
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0, 3: 1.0, 5: 1.0, 10: 1.0}, recall_at_k={1: 0.1, 3: 0.3, 5: 0.5, 10: 1.0}, ndcg_at_k={1: np.float64(1.0), 3: np.float64(1.0), 5: np.float64(1.0), 10: np.float64(1.0)}, mrr=1.0, total_relevant=10, total_queries=1)",
      "tokenization": "TokenizationComparison(query='running', local_tokens=['running'], voyage_tokens=['running'], simple_tokens=['running'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "tokenization",
      "type": "stemming_test",
      "results_count": 2,
      "relevance_scores": [
        0.5,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0}, recall_at_k={1: 0.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=0.0, total_relevant=0, total_queries=1)",
      "tokenization": "TokenizationComparison(query='tokenization', local_tokens=['tokenization'], voyage_tokens=['tokenization'], simple_tokens=['tokenization'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "similarities",
      "type": "stemming_test",
      "results_count": 1,
      "relevance_scores": [
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 1.0}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='similarities', local_tokens=['similarities'], voyage_tokens=['similarities'], simple_tokens=['similarities'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "the best algorithm for search",
      "type": "stopword_test",
      "results_count": 10,
      "relevance_scores": [
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        1.0,
        0.5,
        0.5
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 0.0, 3: 0.0, 5: 0.0, 10: 0.1}, recall_at_k={1: 0.0, 3: 0.0, 5: 0.0, 10: 1.0}, ndcg_at_k={1: np.float64(0.5), 3: np.float64(0.680606056760201), 5: np.float64(0.7467366458934469), 10: np.float64(0.8765170386991245)}, mrr=0.125, total_relevant=1, total_queries=1)",
      "tokenization": "TokenizationComparison(query='the best algorithm for search', local_tokens=['best', 'algorithm', 'search'], voyage_tokens=['the', 'best', 'algorithm', 'for', 'search'], simple_tokens=['the', 'best', 'algorithm', 'for', 'search'], local_results=[], voyage_results=[], simple_results=[])"
    },
    {
      "query": "a function to calculate",
      "type": "stopword_test",
      "results_count": 2,
      "relevance_scores": [
        1.0,
        1.0
      ],
      "quality_metrics": "QualityMetrics(precision_at_k={1: 1.0}, recall_at_k={1: 0.5}, ndcg_at_k={1: np.float64(1.0)}, mrr=1.0, total_relevant=2, total_queries=1)",
      "tokenization": "TokenizationComparison(query='a function to calculate', local_tokens=['function', 'calculate'], voyage_tokens=['a', 'function', 'to', 'calculate'], simple_tokens=['a', 'function', 'to', 'calculate'], local_results=[], voyage_results=[], simple_results=[])"
    }
  ],
  "aggregate_metrics": {
    "avg_precision_at_5": 0.2421052631578947,
    "avg_recall_at_5": 0.18421052631578946,
    "avg_ndcg_at_5": 0.3793966644832195,
    "avg_mrr": 0.6469298245614035,
    "successful_queries": 19,
    "total_queries": 19
  },
  "tokenization_analysis": [
    "TokenizationComparison(query='calculate similarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculate', 'similarity'], simple_tokens=['calculate', 'similarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenize text', local_tokens=['tokenize', 'text'], voyage_tokens=['tokenize', 'text'], simple_tokens=['tokenize', 'text'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='generate embeddings', local_tokens=['generate', 'embeddings'], voyage_tokens=['generate', 'embeddings'], simple_tokens=['generate', 'embeddings'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='BM25Tokenizer', local_tokens=['bm25tokenizer'], voyage_tokens=['bm25tokenizer'], simple_tokens=['bm25tokenizer'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='HybridCodeSearch', local_tokens=['hybrid', 'code', 'search'], voyage_tokens=['hybridcodesearch'], simple_tokens=['hybridcodesearch'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='TokenizationManager', local_tokens=['tokenization', 'manager'], voyage_tokens=['tokenizationmanager'], simple_tokens=['tokenizationmanager'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='cosine similarity', local_tokens=['cosine', 'similarity'], voyage_tokens=['cosine', 'similarity'], simple_tokens=['cosine', 'similarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='stem words', local_tokens=['stem', 'words'], voyage_tokens=['stem', 'words'], simple_tokens=['stem', 'words'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='remove stopwords', local_tokens=['remove', 'stopwords'], voyage_tokens=['remove', 'stopwords'], simple_tokens=['remove', 'stopwords'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='for loop iteration', local_tokens=['loop', 'iteration'], voyage_tokens=['for', 'loop', 'iteration'], simple_tokens=['for', 'loop', 'iteration'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='try except error', local_tokens=['try', 'except', 'error'], voyage_tokens=['try', 'except', 'error'], simple_tokens=['try', 'except', 'error'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='import numpy', local_tokens=['import', 'numpy'], voyage_tokens=['import', 'numpy'], simple_tokens=['import', 'numpy'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='calculateSimilarity', local_tokens=['calculate', 'similarity'], voyage_tokens=['calculatesimilarity'], simple_tokens=['calculatesimilarity'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenizeText', local_tokens=['tokenize', 'text'], voyage_tokens=['tokenizetext'], simple_tokens=['tokenizetext'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='running', local_tokens=['running'], voyage_tokens=['running'], simple_tokens=['running'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='tokenization', local_tokens=['tokenization'], voyage_tokens=['tokenization'], simple_tokens=['tokenization'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='similarities', local_tokens=['similarities'], voyage_tokens=['similarities'], simple_tokens=['similarities'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='the best algorithm for search', local_tokens=['best', 'algorithm', 'search'], voyage_tokens=['the', 'best', 'algorithm', 'for', 'search'], simple_tokens=['the', 'best', 'algorithm', 'for', 'search'], local_results=[], voyage_results=[], simple_results=[])",
    "TokenizationComparison(query='a function to calculate', local_tokens=['function', 'calculate'], voyage_tokens=['a', 'function', 'to', 'calculate'], simple_tokens=['a', 'function', 'to', 'calculate'], local_results=[], voyage_results=[], simple_results=[])"
  ],
  "summary": {
    "overall_quality": "Poor",
    "success_rate": 1.0,
    "key_findings": [
      "Low precision: Many irrelevant results in top positions",
      "Poor recall: Missing many relevant results"
    ]
  }
}