"""
Comprehensive Security Consolidation Validation Tests
=====================================================

Real behavior testing framework for security consolidation validation using
TestContainers methodology proven in database consolidation testing.

Tests all security components integration:
- UnifiedSecurityManager with all security modes
- UnifiedRateLimiter integration and performance
- KeyManager encryption/decryption operations
- SecurityContext creation and validation
- Authentication flows (API key + session token)
- Authorization and access control
- Security audit logging and incident response
- OWASP Top 10 attack resistance
- Fail-secure policy enforcement
- Integration with DatabaseServices

Performance Targets:
- Authentication: <10ms per operation
- Key generation: <5ms per key
- Rate limiting: <2ms per check
- 3-5x improvement over scattered implementations

Security Validation:
- Zero information leakage
- Fail-secure policy enforcement
- Timing attack resistance
- Cryptographic security validation
- Complete audit logging coverage
"""

import asyncio
import gc
import hashlib
import json
import secrets
import statistics
import time
import tracemalloc
from collections import defaultdict
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Tuple

import psutil
import pytest
from src.prompt_improver.database.unified_connection_manager import (
    ManagerMode,
    SecurityContext,
    create_security_context,
    get_unified_manager,
)
from src.prompt_improver.security.authorization import (
    AuthorizationService,
    Permission,
    Role,
)
from src.prompt_improver.security.key_manager import (
    AuditEvent,
    SecurityLevel,
    UnifiedKeyManager,
    get_unified_key_manager,
)
from src.prompt_improver.security.unified_rate_limiter import (
    RateLimitExceeded,
    RateLimitResult,
    RateLimitStatus,
    RateLimitTier,
    UnifiedRateLimiter,
    get_unified_rate_limiter,
)
from src.prompt_improver.security.unified_security_manager import (
    SecurityConfiguration,
    SecurityMode,
    SecurityOperationType,
    SecurityThreatLevel,
    UnifiedSecurityManager,
    create_security_test_adapter,
    get_unified_security_manager,
)


@pytest.fixture(scope="session")
async def postgres_container():
    """Provide real PostgreSQL container for testing."""
    if not TESTCONTAINERS_AVAILABLE:
        pytest.skip("TestContainers not available")
    container = PostgresContainer("postgres:15")
    container.start()
    yield container
    container.stop()


@pytest.fixture(scope="session")
async def redis_container():
    """Provide real Redis container for testing."""
    if not TESTCONTAINERS_AVAILABLE:
        pytest.skip("TestContainers not available")
    container = RedisContainer("redis:7")
    container.start()
    yield container
    container.stop()


@pytest.fixture
async def unified_connection_manager(postgres_container, redis_container):
    """Initialize DatabaseServices with real containers."""
    import os

    os.environ["DATABASE_URL"] = postgres_container.get_connection_url()
    os.environ["REDIS_URL"] = redis_container.get_connection_url()
    manager = get_database_services(ManagerMode.ASYNC_MODERN)
    await manager.initialize()
    yield manager
    await manager.cleanup()


@pytest.fixture
async def unified_security_manager():
    """Initialize UnifiedSecurityManager for testing."""
    manager = await get_unified_security_manager(SecurityMode.API)
    yield manager


@pytest.fixture
async def unified_rate_limiter():
    """Initialize UnifiedRateLimiter for testing."""
    limiter = await get_unified_rate_limiter()
    yield limiter


@pytest.fixture
async def unified_key_manager():
    """Initialize UnifiedKeyManager for testing."""
    manager = get_unified_key_manager()
    yield manager


@pytest.fixture
async def authorization_service():
    """Initialize AuthorizationService for testing."""
    service = AuthorizationService()
    yield service


class SecurityConsolidationValidator:
    """Comprehensive validator for security consolidation using real behavior testing."""

    def __init__(self):
        self.performance_metrics = defaultdict(list)
        self.security_metrics = defaultdict(int)
        self.audit_trail = []
        self.logger_name = f"{__name__}.SecurityConsolidationValidator"

    def _get_memory_usage(self) -> dict[str, float]:
        """Get current memory usage."""
        process = psutil.Process()
        memory_info = process.memory_info()
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,
            "vms_mb": memory_info.vms / 1024 / 1024,
            "percent": process.memory_percent(),
        }

    async def validate_security_manager_modes(
        self, unified_connection_manager
    ) -> dict[str, Any]:
        """Validate UnifiedSecurityManager across all security modes."""
        print("\nðŸ” Testing UnifiedSecurityManager Mode Validation")
        results = {}
        modes_tested = 0
        successful_initializations = 0
        for mode in SecurityMode:
            try:
                start_time = time.perf_counter()
                manager = await get_unified_security_manager(mode)
                status = await manager.get_security_status()
                initialization_time = time.perf_counter() - start_time
                assert status["mode"] == mode.value
                assert status["security_level"] in [
                    "basic",
                    "enhanced",
                    "high",
                    "critical",
                ]
                assert "components" in status
                assert "metrics" in status
                results[mode.value] = {
                    "initialized": True,
                    "initialization_time": initialization_time,
                    "status": status,
                    "security_level": status["security_level"],
                }
                successful_initializations += 1
                modes_tested += 1
                print(
                    f"   âœ… {mode.value}: {initialization_time * 1000:.2f}ms, level: {status['security_level']}"
                )
            except Exception as e:
                results[mode.value] = {"initialized": False, "error": str(e)}
                modes_tested += 1
                print(f"   âŒ {mode.value}: {e}")
        success_rate = successful_initializations / modes_tested
        results["summary"] = {
            "modes_tested": modes_tested,
            "successful_initializations": successful_initializations,
            "success_rate": success_rate,
        }
        assert success_rate >= 1.0, (
            f"Security manager mode initialization success rate {success_rate:.1%} below target (100%)"
        )
        return results

    async def validate_authentication_flows(
        self, unified_security_manager, test_count: int = 10000
    ) -> dict[str, Any]:
        """Validate authentication flows with comprehensive security checks."""
        print(f"\nðŸ”‘ Testing Authentication Flows ({test_count:,} operations)")
        start_time = time.perf_counter()
        successful_auths = 0
        failed_auths = 0
        blocked_agents = 0
        timing_measurements = []
        for i in range(test_count // 2):
            agent_id = f"test_agent_{i}"
            credentials = {
                "api_key": f"valid_key_{i}",
                "token": secrets.token_urlsafe(32),
            }
            auth_start = time.perf_counter()
            try:
                (
                    success,
                    security_context,
                ) = await unified_security_manager.authenticate_agent(
                    agent_id=agent_id,
                    credentials=credentials,
                    additional_context={"test_scenario": "valid_auth"},
                )
                auth_time = time.perf_counter() - auth_start
                timing_measurements.append(auth_time)
                if success:
                    assert security_context.authenticated == True
                    assert security_context.agent_id == agent_id
                    successful_auths += 1
                else:
                    failed_auths += 1
            except Exception as e:
                failed_auths += 1
                print(f"Authentication error for {agent_id}: {e}")
        for i in range(test_count // 2):
            agent_id = f"invalid_agent_{i}"
            credentials = {"api_key": "invalid_key", "token": "invalid_token"}
            auth_start = time.perf_counter()
            try:
                (
                    success,
                    security_context,
                ) = await unified_security_manager.authenticate_agent(
                    agent_id=agent_id,
                    credentials=credentials,
                    additional_context={"test_scenario": "invalid_auth"},
                )
                auth_time = time.perf_counter() - auth_start
                timing_measurements.append(auth_time)
                if not success:
                    assert security_context.authenticated == False
                    failed_auths += 1
                else:
                    print(f"âš ï¸  WARNING: Invalid credentials accepted for {agent_id}")
                    successful_auths += 1
            except Exception as e:
                failed_auths += 1
        total_time = time.perf_counter() - start_time
        total_operations = successful_auths + failed_auths
        avg_auth_time = (
            sum(timing_measurements) / len(timing_measurements)
            if timing_measurements
            else 0
        )
        auth_ops_per_second = total_operations / total_time if total_time > 0 else 0
        security_status = await unified_security_manager.get_security_status()
        results = {
            "total_operations": total_operations,
            "successful_authentications": successful_auths,
            "failed_authentications": failed_auths,
            "blocked_agents": blocked_agents,
            "average_auth_time_ms": avg_auth_time * 1000,
            "auth_ops_per_second": auth_ops_per_second,
            "total_time_seconds": total_time,
            "security_status": security_status,
        }
        print("   ðŸ“Š Authentication Results:")
        print(f"      Total operations: {total_operations:,}")
        print(f"      Successful: {successful_auths:,}")
        print(f"      Failed: {failed_auths:,}")
        print(f"      Average time: {avg_auth_time * 1000:.2f}ms")
        print(f"      Operations/sec: {auth_ops_per_second:.1f}")
        assert avg_auth_time < 0.01, (
            f"Authentication time {avg_auth_time * 1000:.2f}ms exceeds target (10ms)"
        )
        assert auth_ops_per_second >= 100, (
            f"Authentication throughput {auth_ops_per_second:.1f} below target (100 ops/s)"
        )
        return results

    async def validate_rate_limiting_performance(
        self, unified_rate_limiter, test_count: int = 5000
    ) -> dict[str, Any]:
        """Validate rate limiting performance and enforcement."""
        print(f"\nâš¡ Testing Rate Limiting Performance ({test_count:,} operations)")
        timing_measurements = []
        allowed_requests = 0
        rate_limited_requests = 0
        authentication_required = 0
        errors = 0
        start_time = time.perf_counter()
        tiers = [
            RateLimitTier.BASIC.value,
            RateLimitTier.PROFESSIONAL.value,
            RateLimitTier.ENTERPRISE.value,
        ]
        for tier in tiers:
            tier_start = time.perf_counter()
            tier_allowed = 0
            tier_limited = 0
            for i in range(test_count // len(tiers) // 2):
                agent_id = f"tier_{tier}_agent_{i}"
                check_start = time.perf_counter()
                try:
                    status = await unified_rate_limiter.check_rate_limit(
                        agent_id=agent_id, tier=tier, authenticated=True
                    )
                    check_time = time.perf_counter() - check_start
                    timing_measurements.append(check_time)
                    if status.result == RateLimitResult.ALLOWED:
                        allowed_requests += 1
                        tier_allowed += 1
                    elif status.result in [
                        RateLimitResult.RATE_LIMITED,
                        RateLimitResult.BURST_LIMITED,
                    ]:
                        rate_limited_requests += 1
                        tier_limited += 1
                    elif status.result == RateLimitResult.AUTHENTICATION_REQUIRED:
                        authentication_required += 1
                    else:
                        errors += 1
                except Exception as e:
                    errors += 1
                    print(f"Rate limit check error: {e}")
            burst_agent = f"burst_{tier}_agent"
            burst_requests = min(100, test_count // len(tiers) // 2)
            for i in range(burst_requests):
                check_start = time.perf_counter()
                try:
                    status = await unified_rate_limiter.check_rate_limit(
                        agent_id=burst_agent, tier=tier, authenticated=True
                    )
                    check_time = time.perf_counter() - check_start
                    timing_measurements.append(check_time)
                    if status.result == RateLimitResult.ALLOWED:
                        allowed_requests += 1
                        tier_allowed += 1
                    elif status.result in [
                        RateLimitResult.RATE_LIMITED,
                        RateLimitResult.BURST_LIMITED,
                    ]:
                        rate_limited_requests += 1
                        tier_limited += 1
                    else:
                        errors += 1
                except RateLimitExceeded:
                    rate_limited_requests += 1
                    tier_limited += 1
                except Exception as e:
                    errors += 1
            tier_time = time.perf_counter() - tier_start
            print(
                f"   ðŸ“ˆ {tier}: {tier_allowed} allowed, {tier_limited} limited in {tier_time:.2f}s"
            )
        total_time = time.perf_counter() - start_time
        total_operations = (
            allowed_requests + rate_limited_requests + authentication_required + errors
        )
        avg_check_time = (
            sum(timing_measurements) / len(timing_measurements)
            if timing_measurements
            else 0
        )
        rate_limit_ops_per_second = (
            total_operations / total_time if total_time > 0 else 0
        )
        results = {
            "total_operations": total_operations,
            "allowed_requests": allowed_requests,
            "rate_limited_requests": rate_limited_requests,
            "authentication_required": authentication_required,
            "errors": errors,
            "average_check_time_ms": avg_check_time * 1000,
            "rate_limit_ops_per_second": rate_limit_ops_per_second,
            "total_time_seconds": total_time,
        }
        print("   ðŸ“Š Rate Limiting Results:")
        print(f"      Total operations: {total_operations:,}")
        print(f"      Allowed: {allowed_requests:,}")
        print(f"      Rate limited: {rate_limited_requests:,}")
        print(f"      Average time: {avg_check_time * 1000:.2f}ms")
        print(f"      Operations/sec: {rate_limit_ops_per_second:.1f}")
        assert avg_check_time < 0.002, (
            f"Rate limit check time {avg_check_time * 1000:.2f}ms exceeds target (2ms)"
        )
        assert rate_limit_ops_per_second >= 500, (
            f"Rate limiting throughput {rate_limit_ops_per_second:.1f} below target (500 ops/s)"
        )
        assert errors == 0, f"Rate limiting errors occurred: {errors}"
        return results

    async def validate_key_manager_operations(
        self, unified_key_manager, test_count: int = 1000
    ) -> dict[str, Any]:
        """Validate KeyManager encryption/decryption operations."""
        print(f"\nðŸ”‘ Testing KeyManager Operations ({test_count:,} operations)")
        key_generation_times = []
        encryption_times = []
        decryption_times = []
        successful_operations = 0
        failed_operations = 0
        start_time = time.perf_counter()
        generated_keys = []
        for i in range(min(test_count // 10, 100)):
            gen_start = time.perf_counter()
            try:
                key_id = unified_key_manager.generate_key()
                gen_time = time.perf_counter() - gen_start
                key_generation_times.append(gen_time)
                generated_keys.append(key_id)
                successful_operations += 1
            except Exception as e:
                failed_operations += 1
                print(f"Key generation error: {e}")
        test_data_samples = [
            b"small data",
            b"medium sized data that is longer than the small sample" * 10,
            b"large data sample" * 100,
            json.dumps({"complex": "data", "with": {"nested": "structures"}}).encode(),
            secrets.token_bytes(1024),
        ]
        for i in range(test_count):
            try:
                key_id = (
                    generated_keys[i % len(generated_keys)] if generated_keys else None
                )
                test_data = test_data_samples[i % len(test_data_samples)]
                enc_start = time.perf_counter()
                encrypted_data, used_key_id = unified_key_manager.encrypt(
                    test_data, key_id
                )
                enc_time = time.perf_counter() - enc_start
                encryption_times.append(enc_time)
                dec_start = time.perf_counter()
                decrypted_data = unified_key_manager.decrypt(
                    encrypted_data, used_key_id
                )
                dec_time = time.perf_counter() - dec_start
                decryption_times.append(dec_time)
                assert decrypted_data == test_data, (
                    f"Data integrity check failed for operation {i}"
                )
                successful_operations += 2
            except Exception as e:
                failed_operations += 2
                print(f"Encryption/decryption error for operation {i}: {e}")
        total_time = time.perf_counter() - start_time
        avg_key_gen_time = (
            sum(key_generation_times) / len(key_generation_times)
            if key_generation_times
            else 0
        )
        avg_encryption_time = (
            sum(encryption_times) / len(encryption_times) if encryption_times else 0
        )
        avg_decryption_time = (
            sum(decryption_times) / len(decryption_times) if decryption_times else 0
        )
        total_operations = successful_operations + failed_operations
        crypto_ops_per_second = total_operations / total_time if total_time > 0 else 0
        key_status = unified_key_manager.get_security_status()
        results = {
            "total_operations": total_operations,
            "successful_operations": successful_operations,
            "failed_operations": failed_operations,
            "keys_generated": len(generated_keys),
            "avg_key_generation_time_ms": avg_key_gen_time * 1000,
            "avg_encryption_time_ms": avg_encryption_time * 1000,
            "avg_decryption_time_ms": avg_decryption_time * 1000,
            "crypto_ops_per_second": crypto_ops_per_second,
            "total_time_seconds": total_time,
            "key_manager_status": key_status,
        }
        print("   ðŸ“Š KeyManager Results:")
        print(f"      Total operations: {total_operations:,}")
        print(f"      Keys generated: {len(generated_keys)}")
        print(f"      Key generation: {avg_key_gen_time * 1000:.2f}ms avg")
        print(f"      Encryption: {avg_encryption_time * 1000:.2f}ms avg")
        print(f"      Decryption: {avg_decryption_time * 1000:.2f}ms avg")
        print(f"      Operations/sec: {crypto_ops_per_second:.1f}")
        assert avg_key_gen_time < 0.005, (
            f"Key generation time {avg_key_gen_time * 1000:.2f}ms exceeds target (5ms)"
        )
        assert avg_encryption_time < 0.001, (
            f"Encryption time {avg_encryption_time * 1000:.2f}ms exceeds target (1ms)"
        )
        assert avg_decryption_time < 0.001, (
            f"Decryption time {avg_decryption_time * 1000:.2f}ms exceeds target (1ms)"
        )
        assert failed_operations == 0, (
            f"Cryptographic operations failed: {failed_operations}"
        )
        return results

    async def validate_security_audit_logging(
        self, unified_security_manager
    ) -> dict[str, Any]:
        """Validate security audit logging and incident response."""
        print("\nðŸ“‹ Testing Security Audit Logging & Incident Response")
        incidents_created = 0
        incidents_resolved = 0
        threat_levels = [
            SecurityThreatLevel.LOW,
            SecurityThreatLevel.MEDIUM,
            SecurityThreatLevel.HIGH,
        ]
        operation_types = [
            SecurityOperationType.AUTHENTICATION,
            SecurityOperationType.AUTHORIZATION,
            SecurityOperationType.VALIDATION,
        ]
        for threat_level in threat_levels:
            for operation_type in operation_types:
                agent_id = f"test_agent_{threat_level.value}_{operation_type.value}"
                test_adapter = await create_security_test_adapter(SecurityMode.API)
                incident_id = await test_adapter.simulate_security_incident(
                    threat_level=threat_level, agent_id=agent_id
                )
                if incident_id != "no_incident_created":
                    incidents_created += 1
        all_incidents = await unified_security_manager.get_security_incidents(limit=100)
        recent_incidents = await unified_security_manager.get_security_incidents(
            limit=50, threat_level=SecurityThreatLevel.HIGH
        )
        security_status = await unified_security_manager.get_security_status()
        results = {
            "incidents_created": incidents_created,
            "total_incidents_recorded": len(all_incidents),
            "high_threat_incidents": len(recent_incidents),
            "active_incidents": security_status["metrics"].get("active_incidents", 0),
            "resolved_incidents": security_status["metrics"].get(
                "resolved_incidents", 0
            ),
            "security_violations": security_status["metrics"].get(
                "security_violations", 0
            ),
            "audit_status": security_status,
        }
        print("   ðŸ“Š Audit Logging Results:")
        print(f"      Incidents created: {incidents_created}")
        print(f"      Total recorded: {len(all_incidents)}")
        print(f"      High threat: {len(recent_incidents)}")
        print(f"      Active: {results['active_incidents']}")
        print(f"      Resolved: {results['resolved_incidents']}")
        assert incidents_created > 0, "No security incidents were created"
        assert len(all_incidents) >= incidents_created, (
            "Not all incidents were recorded"
        )
        assert "metrics" in security_status, "Security metrics not available"
        assert "uptime_seconds" in security_status, (
            "Security manager uptime not tracked"
        )
        return results

    async def validate_fail_secure_policies(
        self, unified_security_manager, unified_rate_limiter
    ) -> dict[str, Any]:
        """Validate fail-secure policies under error conditions."""
        print("\nðŸ›¡ï¸  Testing Fail-Secure Policy Enforcement")
        fail_secure_tests = 0
        fail_secure_successes = 0
        try:
            success, context = await unified_security_manager.authenticate_agent(
                agent_id=None,
                credentials={"corrupted": "data"},
                additional_context={"test": "fail_secure_auth"},
            )
            fail_secure_tests += 1
            if not success and (not context.authenticated):
                fail_secure_successes += 1
                print("   âœ… Authentication fails secure with invalid data")
            else:
                print("   âŒ Authentication fails open - SECURITY VULNERABILITY")
        except Exception:
            fail_secure_tests += 1
            fail_secure_successes += 1
            print("   âœ… Authentication fails secure with exception")
        try:
            status = await unified_rate_limiter.check_rate_limit(
                agent_id="test_agent", tier="basic", authenticated=False
            )
            fail_secure_tests += 1
            if status.result == RateLimitResult.AUTHENTICATION_REQUIRED:
                fail_secure_successes += 1
                print("   âœ… Rate limiting requires authentication")
            else:
                print(
                    "   âŒ Rate limiting allows unauthenticated access - SECURITY VULNERABILITY"
                )
        except Exception:
            fail_secure_tests += 1
            fail_secure_successes += 1
            print("   âœ… Rate limiting fails secure with exception")
        try:
            test_context = await create_security_context(
                agent_id="test_agent", tier="basic", authenticated=True
            )
            test_context.created_at = time.time() - 7200
            is_authorized = await unified_security_manager.authorize_operation(
                security_context=test_context,
                operation="test_operation",
                resource="test_resource",
            )
            fail_secure_tests += 1
            if not is_authorized:
                fail_secure_successes += 1
                print("   âœ… Authorization fails secure with expired context")
            else:
                print(
                    "   âŒ Authorization allows expired context - SECURITY VULNERABILITY"
                )
        except Exception:
            fail_secure_tests += 1
            fail_secure_successes += 1
            print("   âœ… Authorization fails secure with exception")
        fail_secure_rate = (
            fail_secure_successes / fail_secure_tests if fail_secure_tests > 0 else 0
        )
        results = {
            "fail_secure_tests": fail_secure_tests,
            "fail_secure_successes": fail_secure_successes,
            "fail_secure_rate": fail_secure_rate,
            "security_vulnerabilities": fail_secure_tests - fail_secure_successes,
        }
        print("   ðŸ“Š Fail-Secure Results:")
        print(f"      Tests conducted: {fail_secure_tests}")
        print(f"      Fail-secure successes: {fail_secure_successes}")
        print(f"      Fail-secure rate: {fail_secure_rate:.1%}")
        print(f"      Security vulnerabilities: {results['security_vulnerabilities']}")
        assert fail_secure_rate >= 1.0, (
            f"Fail-secure compliance {fail_secure_rate:.1%} below target (100%)"
        )
        assert results["security_vulnerabilities"] == 0, (
            f"Security vulnerabilities detected: {results['security_vulnerabilities']}"
        )
        return results

    async def validate_timing_attack_resistance(
        self, unified_security_manager, sample_size: int = 1000
    ) -> dict[str, Any]:
        """Validate timing attack resistance in authentication."""
        print(f"\nâ±ï¸  Testing Timing Attack Resistance ({sample_size:,} samples)")
        valid_auth_times = []
        invalid_auth_times = []
        for i in range(sample_size // 2):
            agent_id = f"valid_agent_{i}"
            credentials = {"api_key": f"valid_key_{i}"}
            start_time = time.perf_counter()
            try:
                success, context = await unified_security_manager.authenticate_agent(
                    agent_id=agent_id, credentials=credentials
                )
                auth_time = time.perf_counter() - start_time
                valid_auth_times.append(auth_time)
            except Exception:
                auth_time = time.perf_counter() - start_time
                valid_auth_times.append(auth_time)
        for i in range(sample_size // 2):
            agent_id = f"invalid_agent_{i}"
            credentials = {"api_key": "invalid_key"}
            start_time = time.perf_counter()
            try:
                success, context = await unified_security_manager.authenticate_agent(
                    agent_id=agent_id, credentials=credentials
                )
                auth_time = time.perf_counter() - start_time
                invalid_auth_times.append(auth_time)
            except Exception:
                auth_time = time.perf_counter() - start_time
                invalid_auth_times.append(auth_time)
        valid_avg = (
            sum(valid_auth_times) / len(valid_auth_times) if valid_auth_times else 0
        )
        invalid_avg = (
            sum(invalid_auth_times) / len(invalid_auth_times)
            if invalid_auth_times
            else 0
        )
        valid_std = (
            statistics.stdev(valid_auth_times) if len(valid_auth_times) > 1 else 0
        )
        invalid_std = (
            statistics.stdev(invalid_auth_times) if len(invalid_auth_times) > 1 else 0
        )
        timing_difference = abs(valid_avg - invalid_avg)
        timing_difference_ratio = (
            timing_difference / max(valid_avg, invalid_avg)
            if max(valid_avg, invalid_avg) > 0
            else 0
        )
        results = {
            "valid_auth_samples": len(valid_auth_times),
            "invalid_auth_samples": len(invalid_auth_times),
            "valid_avg_time_ms": valid_avg * 1000,
            "invalid_avg_time_ms": invalid_avg * 1000,
            "valid_std_dev_ms": valid_std * 1000,
            "invalid_std_dev_ms": invalid_std * 1000,
            "timing_difference_ms": timing_difference * 1000,
            "timing_difference_ratio": timing_difference_ratio,
            "timing_attack_resistant": timing_difference_ratio < 0.1,
        }
        print("   ðŸ“Š Timing Attack Resistance Results:")
        print(
            f"      Valid auth avg: {valid_avg * 1000:.2f}ms (Â±{valid_std * 1000:.2f})"
        )
        print(
            f"      Invalid auth avg: {invalid_avg * 1000:.2f}ms (Â±{invalid_std * 1000:.2f})"
        )
        print(
            f"      Timing difference: {timing_difference * 1000:.2f}ms ({timing_difference_ratio:.1%})"
        )
        print(
            f"      Timing attack resistant: {('âœ…' if results['timing_attack_resistant'] else 'âŒ')}"
        )
        assert timing_difference_ratio < 0.1, (
            f"Timing difference {timing_difference_ratio:.1%} indicates timing attack vulnerability (should be <10%)"
        )
        return results


class TestSecurityConsolidation:
    """Main test class for comprehensive security consolidation validation."""

    @pytest.mark.asyncio
    async def test_security_manager_initialization(self, unified_connection_manager):
        """Test UnifiedSecurityManager initialization across all modes."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_security_manager_modes(
            unified_connection_manager
        )
        print("\nâœ… SecurityConsolidationValidator class implemented successfully")
        assert results["summary"]["success_rate"] >= 1.0
        assert all(
            mode_result.get("initialized", False)
            for mode_result in results.values()
            if isinstance(mode_result, dict) and "initialized" in mode_result
        )

    @pytest.mark.asyncio
    async def test_authentication_performance(self, unified_security_manager):
        """Test authentication flow performance and security."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_authentication_flows(
            unified_security_manager, test_count=10000
        )
        print("\nâœ… Authentication flow performance validation completed")
        assert results["average_auth_time_ms"] < 10.0
        assert results["auth_ops_per_second"] >= 100
        assert results["successful_authentications"] > 0

    @pytest.mark.asyncio
    async def test_rate_limiting_performance(self, unified_rate_limiter):
        """Test rate limiting performance and enforcement."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_rate_limiting_performance(
            unified_rate_limiter, test_count=5000
        )
        print("\nâœ… Rate limiting performance validation completed")
        assert results["average_check_time_ms"] < 2.0
        assert results["rate_limit_ops_per_second"] >= 500
        assert results["errors"] == 0

    @pytest.mark.asyncio
    async def test_key_manager_operations(self, unified_key_manager):
        """Test KeyManager encryption/decryption operations."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_key_manager_operations(
            unified_key_manager, test_count=1000
        )
        print("\nâœ… KeyManager operations validation completed")
        assert results["avg_key_generation_time_ms"] < 5.0
        assert results["avg_encryption_time_ms"] < 1.0
        assert results["avg_decryption_time_ms"] < 1.0
        assert results["failed_operations"] == 0

    @pytest.mark.asyncio
    async def test_security_audit_logging(self, unified_security_manager):
        """Test security audit logging and incident response."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_security_audit_logging(
            unified_security_manager
        )
        print("\nâœ… Security audit logging validation completed")
        assert results["incidents_created"] > 0
        assert results["total_incidents_recorded"] >= results["incidents_created"]
        assert "metrics" in results["audit_status"]

    @pytest.mark.asyncio
    async def test_fail_secure_policies(
        self, unified_security_manager, unified_rate_limiter
    ):
        """Test fail-secure policy enforcement under error conditions."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_fail_secure_policies(
            unified_security_manager, unified_rate_limiter
        )
        print("\nâœ… Fail-secure policy validation completed")
        assert results["fail_secure_rate"] >= 1.0
        assert results["security_vulnerabilities"] == 0

    @pytest.mark.asyncio
    async def test_timing_attack_resistance(self, unified_security_manager):
        """Test timing attack resistance in authentication."""
        validator = SecurityConsolidationValidator()
        results = await validator.validate_timing_attack_resistance(
            unified_security_manager, sample_size=1000
        )
        print("\nâœ… Timing attack resistance validation completed")
        assert results["timing_attack_resistant"] == True
        assert results["timing_difference_ratio"] < 0.1

    @pytest.mark.asyncio
    async def test_overall_security_consolidation_improvement(
        self,
        unified_connection_manager,
        unified_security_manager,
        unified_rate_limiter,
        unified_key_manager,
    ):
        """Test overall security consolidation improvement metrics."""
        print("\nðŸŽ¯ Testing Overall Security Consolidation Improvement")
        validator = SecurityConsolidationValidator()
        gc.collect()
        tracemalloc.start()
        start_memory = validator._get_memory_usage()
        start_time = time.perf_counter()
        total_operations = 0
        auth_results = await validator.validate_authentication_flows(
            unified_security_manager, test_count=1000
        )
        total_operations += auth_results["total_operations"]
        rate_results = await validator.validate_rate_limiting_performance(
            unified_rate_limiter, test_count=2000
        )
        total_operations += rate_results["total_operations"]
        crypto_results = await validator.validate_key_manager_operations(
            unified_key_manager, test_count=500
        )
        total_operations += crypto_results["total_operations"]
        total_time = time.perf_counter() - start_time
        end_memory = validator._get_memory_usage()
        overall_ops_per_second = total_operations / total_time
        memory_delta = end_memory["rss_mb"] - start_memory["rss_mb"]
        baseline_ops_per_sec = 50
        improvement_factor = overall_ops_per_second / baseline_ops_per_sec
        auth_weight = 0.4
        rate_limit_weight = 0.3
        crypto_weight = 0.3
        weighted_improvement = (
            auth_results["auth_ops_per_second"] / 100 * auth_weight
            + rate_results["rate_limit_ops_per_second"] / 500 * rate_limit_weight
            + crypto_results["crypto_ops_per_second"] / 200 * crypto_weight
        )
        results = {
            "total_operations": total_operations,
            "overall_ops_per_second": overall_ops_per_second,
            "total_time_seconds": total_time,
            "memory_delta_mb": memory_delta,
            "improvement_factor": improvement_factor,
            "weighted_improvement": weighted_improvement,
            "performance_targets_met": {
                "authentication": auth_results["average_auth_time_ms"] < 10.0,
                "rate_limiting": rate_results["average_check_time_ms"] < 2.0,
                "cryptography": crypto_results["avg_encryption_time_ms"] < 1.0,
            },
        }
        print("\nðŸ“Š Overall Security Consolidation Results:")
        print(f"   Total operations: {total_operations:,}")
        print(f"   Operations/sec: {overall_ops_per_second:.1f}")
        print(f"   Memory delta: {memory_delta:.2f} MB")
        print(f"   Improvement factor: {improvement_factor:.1f}x")
        print(f"   Weighted improvement: {weighted_improvement:.1f}x")
        print(
            f"   All performance targets met: {all(results['performance_targets_met'].values())}"
        )
        assert improvement_factor >= 3.0, (
            f"Overall improvement {improvement_factor:.1f}x below target (3-5x)"
        )
        assert weighted_improvement >= 2.0, (
            f"Weighted improvement {weighted_improvement:.1f}x below target (2x)"
        )
        assert all(results["performance_targets_met"].values()), (
            "Not all performance targets were met"
        )
        assert memory_delta < 50, (
            f"Memory usage {memory_delta:.1f}MB too high for test workload"
        )
        print(
            f"\nâœ… Security consolidation targets achieved! Overall improvement: {improvement_factor:.1f}x"
        )
        tracemalloc.stop()


pytestmark = pytest.mark.performance
