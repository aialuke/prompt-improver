"""Real concurrency tests for DistributedLockManager.

Tests comprehensive distributed locking functionality with real concurrent scenarios:
- Lock acquisition and release under high concurrency
- Token-based security with ownership validation
- Automatic expiration and cleanup mechanisms
- Retry logic with exponential backoff
- Context manager patterns for automatic cleanup
- Performance validation under concurrent load

Integration tests using mock Redis that simulates real Redis behavior.
"""

import asyncio
import time
from typing import Any

import pytest

from prompt_improver.database.services.locking.lock_manager import (
    DistributedLockManager,
    LockConfig,
    create_lock_manager,
)


class MockRedisClient:
    """Mock Redis client that simulates real Redis SET NX EX and Lua script behavior."""

    def __init__(self, should_fail: bool = False, response_delay_ms: float = 1.0):
        self.should_fail = should_fail
        self.response_delay_ms = response_delay_ms

        # Simulate Redis key-value store with expiration
        self._data: dict[str, dict[str, Any]] = {}  # key -> {value, expires_at}
        self._lock = asyncio.Lock()  # Simulate Redis atomicity

        # Operation counters
        self.set_count = 0
        self.eval_count = 0
        self.get_count = 0

    async def _sleep_if_needed(self):
        """Simulate network latency."""
        if self.response_delay_ms > 0:
            await asyncio.sleep(self.response_delay_ms / 1000.0)

    async def _expire_keys(self):
        """Remove expired keys (simulate Redis expiration)."""
        current_time = time.time()
        expired_keys = []

        for key, data in self._data.items():
            if 'expires_at' in data and current_time > data['expires_at']:
                expired_keys.append(key)

        for key in expired_keys:
            del self._data[key]

    async def set(self, key: str, value: str, nx: bool = False, ex: int | None = None) -> bool:
        """Mock Redis SET command with NX and EX options."""
        await self._sleep_if_needed()

        if self.should_fail:
            raise Exception("Mock Redis connection failure")

        async with self._lock:
            await self._expire_keys()
            self.set_count += 1

            # NX: only set if key doesn't exist
            if nx and key in self._data:
                return False

            # Set the value
            data = {'value': value}
            if ex:
                data['expires_at'] = time.time() + ex

            self._data[key] = data
            return True

    async def get(self, key: str) -> str:
        """Mock Redis GET command."""
        await self._sleep_if_needed()

        if self.should_fail:
            raise Exception("Mock Redis connection failure")

        async with self._lock:
            await self._expire_keys()
            self.get_count += 1

            if key not in self._data:
                return None

            return self._data[key]['value']

    async def eval(self, script: str, num_keys: int, *args) -> int:
        """Mock Redis EVAL command for Lua scripts."""
        await self._sleep_if_needed()

        if self.should_fail:
            raise Exception("Mock Redis connection failure")

        async with self._lock:
            await self._expire_keys()
            self.eval_count += 1

            if num_keys == 0:
                return 0

            key = args[0]

            # Release script: if redis.call("get", KEYS[1]) == ARGV[1] then return redis.call("del", KEYS[1]) else return 0 end
            if "del" in script and len(args) >= 2:
                expected_value = args[1]
                if key in self._data and self._data[key]['value'] == expected_value:
                    del self._data[key]
                    return 1
                return 0

            # Extend script: if redis.call("get", KEYS[1]) == ARGV[1] then return redis.call("expire", KEYS[1], ARGV[2]) else return 0 end
            if "expire" in script and len(args) >= 3:
                expected_value = args[1]
                timeout = int(args[2])
                if key in self._data and self._data[key]['value'] == expected_value:
                    self._data[key]['expires_at'] = time.time() + timeout
                    return 1
                return 0

            return 0

    def get_stats(self) -> dict[str, Any]:
        """Get mock Redis statistics."""
        return {
            "active_keys": len(self._data),
            "set_operations": self.set_count,
            "eval_operations": self.eval_count,
            "get_operations": self.get_count,
        }


class MockL2RedisService:
    """Mock L2RedisService that adapts MockRedisClient for compatibility."""

    def __init__(self, mock_redis_client):
        """Initialize with a MockRedisClient for compatibility."""
        self._mock_redis = mock_redis_client
        self._available = True

        # Performance tracking like real L2RedisService
        self._total_operations = 0
        self._successful_operations = 0
        self._failed_operations = 0

    def _track_operation(self, start_time: float, success: bool, operation: str, key: str = "") -> None:
        """Track operation performance."""
        self._total_operations += 1
        if success:
            self._successful_operations += 1
        else:
            self._failed_operations += 1

    def is_available(self) -> bool:
        """Check if Redis client is available."""
        return self._available and not self._mock_redis.should_fail

    async def lock_acquire(self, key: str, token: str, ttl_seconds: int) -> bool:
        """Acquire distributed lock using mock Redis client."""
        start_time = time.perf_counter()

        try:
            if not self.is_available():
                self._track_operation(start_time, False, "LOCK_ACQUIRE", key)
                return False

            # Use mock Redis SET NX EX
            result = await self._mock_redis.set(key, token, nx=True, ex=ttl_seconds)
            success = bool(result)
            self._track_operation(start_time, success, "LOCK_ACQUIRE", key)
            return success

        except Exception:
            self._track_operation(start_time, False, "LOCK_ACQUIRE", key)
            return False

    async def lock_release(self, key: str, token: str) -> bool:
        """Release distributed lock using mock Redis client."""
        start_time = time.perf_counter()

        try:
            if not self.is_available():
                self._track_operation(start_time, False, "LOCK_RELEASE", key)
                return False

            # Simulate Lua script behavior: check token and delete if match
            stored_value = await self._mock_redis.get(key)
            if stored_value == token:
                # Simulate deletion by removing from mock storage
                if key in self._mock_redis._data:
                    del self._mock_redis._data[key]
                result = True
            else:
                result = False

            self._track_operation(start_time, result, "LOCK_RELEASE", key)
            return result

        except Exception:
            self._track_operation(start_time, False, "LOCK_RELEASE", key)
            return False

    async def lock_extend(self, key: str, token: str, ttl_seconds: int) -> bool:
        """Extend distributed lock using mock Redis client."""
        start_time = time.perf_counter()

        try:
            if not self.is_available():
                self._track_operation(start_time, False, "LOCK_EXTEND", key)
                return False

            # Simulate Lua script behavior: check token and extend if match
            stored_value = await self._mock_redis.get(key)
            if stored_value == token:
                # Simulate extension by updating expiration
                if key in self._mock_redis._data:
                    self._mock_redis._data[key]['expires_at'] = time.time() + ttl_seconds
                result = True
            else:
                result = False

            self._track_operation(start_time, result, "LOCK_EXTEND", key)
            return result

        except Exception:
            self._track_operation(start_time, False, "LOCK_EXTEND", key)
            return False

    async def close(self) -> None:
        """Close connection gracefully."""

    def get_stats(self) -> dict:
        """Get performance statistics."""
        return {
            "total_operations": self._total_operations,
            "successful_operations": self._successful_operations,
            "failed_operations": self._failed_operations,
        }


class TestDistributedLockManager:
    """Test DistributedLockManager core functionality."""

    def test_lock_manager_creation(self):
        """Test lock manager initialization."""
        redis_client = MockRedisClient()
        config = LockConfig(default_timeout_seconds=10)

        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis, config)
        assert manager.config.default_timeout_seconds == 10
        assert len(manager._active_locks) == 0
        assert manager.total_acquire_attempts == 0

    @pytest.mark.asyncio
    async def test_basic_lock_acquire_release(self):
        """Test basic lock acquisition and release."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # Acquire lock
        token = await manager.acquire_lock("test_resource", timeout=30)
        assert token is not None
        assert len(token) > 10  # UUID should be substantial

        # Verify lock is tracked
        assert "test_resource" in manager._active_locks
        lock_info = manager._active_locks["test_resource"]
        assert lock_info.key == "test_resource"
        assert lock_info.token == token
        assert lock_info.timeout_seconds == 30

        # Release lock
        released = await manager.release_lock("test_resource", token)
        assert released is True
        assert "test_resource" not in manager._active_locks

        print("âœ… Basic lock acquire/release functionality")

    @pytest.mark.asyncio
    async def test_lock_acquisition_conflict(self):
        """Test lock acquisition when key already locked."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # First acquisition should succeed
        token1 = await manager.acquire_lock("shared_resource", timeout=10)
        assert token1 is not None

        # Second acquisition should fail (no retry by default in this test)
        config = LockConfig(retry_attempts=0)
        mock_l2_redis2 = MockL2RedisService(redis_client)
        manager2 = DistributedLockManager(mock_l2_redis2, config)
        token2 = await manager2.acquire_lock("shared_resource", timeout=10, retry=False)
        assert token2 is None

        # Release first lock
        released = await manager.release_lock("shared_resource", token1)
        assert released is True

        # Now second acquisition should succeed
        token3 = await manager2.acquire_lock("shared_resource", timeout=10, retry=False)
        assert token3 is not None

        await manager2.release_lock("shared_resource", token3)

        print("âœ… Lock acquisition conflict handling")

    @pytest.mark.asyncio
    async def test_token_based_security(self):
        """Test token-based lock ownership validation."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # Acquire lock
        token = await manager.acquire_lock("secure_resource")
        assert token is not None

        # Try to release with wrong token
        fake_token = "fake-token-12345"
        released_wrong = await manager.release_lock("secure_resource", fake_token)
        assert released_wrong is False

        # Lock should still be active
        assert "secure_resource" in manager._active_locks

        # Release with correct token
        released_correct = await manager.release_lock("secure_resource", token)
        assert released_correct is True
        assert "secure_resource" not in manager._active_locks

        print("âœ… Token-based security validation")

    @pytest.mark.asyncio
    async def test_lock_extension(self):
        """Test lock timeout extension functionality."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # Acquire lock with short timeout
        token = await manager.acquire_lock("extendable_resource", timeout=5)
        assert token is not None

        original_expires_at = manager._active_locks["extendable_resource"].expires_at

        # Wait a bit then extend
        await asyncio.sleep(0.1)
        extended = await manager.extend_lock("extendable_resource", token, timeout=20)
        assert extended is True

        # Verify extension
        new_expires_at = manager._active_locks["extendable_resource"].expires_at
        assert new_expires_at > original_expires_at

        # Verify new timeout
        lock_info = manager._active_locks["extendable_resource"]
        assert lock_info.timeout_seconds == 20

        # Clean up
        await manager.release_lock("extendable_resource", token)

        print("âœ… Lock extension functionality")

    @pytest.mark.asyncio
    async def test_context_manager(self):
        """Test context manager for automatic lock management."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # Use context manager
        async with manager.acquire_lock_context("context_resource", timeout=15) as token:
            assert token is not None
            assert "context_resource" in manager._active_locks

            lock_info = manager._active_locks["context_resource"]
            assert lock_info.token == token
            assert lock_info.timeout_seconds == 15

        # Lock should be automatically released
        assert "context_resource" not in manager._active_locks

        print("âœ… Context manager automatic cleanup")

    @pytest.mark.asyncio
    async def test_context_manager_exception_handling(self):
        """Test context manager cleanup on exceptions."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        acquired_token = None
        try:
            async with manager.acquire_lock_context("exception_resource") as token:
                acquired_token = token
                assert token is not None
                assert "exception_resource" in manager._active_locks

                # Raise exception to test cleanup
                raise ValueError("Test exception")

        except ValueError:
            pass  # Expected exception

        # Lock should still be cleaned up despite exception
        assert "exception_resource" not in manager._active_locks
        assert acquired_token is not None  # Verify lock was actually acquired

        print("âœ… Context manager exception cleanup")

    @pytest.mark.asyncio
    async def test_retry_logic(self):
        """Test retry logic with exponential backoff."""
        redis_client = MockRedisClient()
        config = LockConfig(retry_attempts=3, retry_delay_seconds=0.01)  # Fast retry for testing
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis, config)

        # Block the resource first
        blocking_token = await manager.acquire_lock("retry_resource", timeout=1)
        assert blocking_token is not None

        # Try to acquire with retry (should fail but retry)
        start_time = time.time()
        failed_token = await manager.acquire_lock("retry_resource", timeout=1, retry=True)
        elapsed = time.time() - start_time

        # Should have failed but taken time for retries
        assert failed_token is None
        assert elapsed > 0.03  # Should have taken time for 3 retry delays

        # Verify retry attempts were counted
        assert manager.failed_acquisitions > 0

        # Clean up
        await manager.release_lock("retry_resource", blocking_token)

        print(f"âœ… Retry logic with backoff (took {elapsed:.3f}s for retries)")


@pytest.mark.asyncio
class TestDistributedLockConcurrency:
    """Test DistributedLockManager under concurrent load."""

    async def test_high_concurrency_lock_contention(self):
        """Test lock manager under high concurrent contention."""
        redis_client = MockRedisClient(response_delay_ms=2.0)  # Simulate network latency
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        resource_key = "high_contention_resource"
        num_workers = 20
        work_duration = 0.05  # 50ms work duration

        successful_acquisitions = []
        failed_acquisitions = []

        async def worker(worker_id: int):
            """Worker that tries to acquire lock and do work."""
            async with manager.acquire_lock_context(resource_key, timeout=5) as token:
                if token:
                    successful_acquisitions.append(worker_id)
                    # Simulate work
                    await asyncio.sleep(work_duration)
                else:
                    failed_acquisitions.append(worker_id)

        # Run all workers concurrently
        start_time = time.time()
        await asyncio.gather(*[worker(i) for i in range(num_workers)])
        total_time = time.time() - start_time

        # Verify exclusivity - only one should succeed at a time
        # But some may succeed sequentially as locks are released
        assert len(successful_acquisitions) > 0
        print(f"    Successful acquisitions: {len(successful_acquisitions)}")
        print(f"    Failed acquisitions: {len(failed_acquisitions)}")
        print(f"    Total time: {total_time:.3f}s")

        # Should have some successes and failures under contention
        assert len(successful_acquisitions) + len(failed_acquisitions) == num_workers

        print("âœ… High concurrency lock contention handled correctly")

    async def test_multiple_resource_locking(self):
        """Test concurrent locking of different resources."""
        redis_client = MockRedisClient(response_delay_ms=1.0)
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        num_resources = 10
        workers_per_resource = 3

        results = {}

        async def resource_worker(resource_id: int, worker_id: int):
            """Worker for specific resource."""
            resource_key = f"resource_{resource_id}"

            async with manager.acquire_lock_context(resource_key, timeout=10) as token:
                if token:
                    if resource_id not in results:
                        results[resource_id] = []
                    results[resource_id].append(worker_id)

                    # Simulate work
                    await asyncio.sleep(0.02)

        # Create workers for all resources
        tasks = []
        for resource_id in range(num_resources):
            tasks.extend(resource_worker(resource_id, worker_id) for worker_id in range(workers_per_resource))

        # Run all workers concurrently
        await asyncio.gather(*tasks)

        # Verify each resource had some successful workers
        assert len(results) > 0
        print(f"    Resources accessed: {len(results)}")

        # Different resources should be able to be locked simultaneously
        total_workers = sum(len(workers) for workers in results.values())
        print(f"    Total successful workers: {total_workers}")

        print("âœ… Multiple resource concurrent locking")

    async def test_lock_cleanup_under_load(self):
        """Test background cleanup functionality under load."""
        redis_client = MockRedisClient()
        config = LockConfig(default_timeout_seconds=1)  # Short timeout for testing
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis, config)

        # Override cleanup interval for faster testing
        manager._cleanup_interval = 0.5

        # Start cleanup task
        await manager.start_cleanup_task()

        try:
            # Create many short-lived locks
            num_locks = 20  # Reduced for more reliable testing
            for i in range(num_locks):
                token = await manager.acquire_lock(f"cleanup_test_{i}", timeout=1)
                if token:
                    # Don't release - let them expire
                    pass

            initial_count = len(manager._active_locks)
            print(f"    Created {initial_count} locks")

            # Wait for locks to expire and cleanup to run
            await asyncio.sleep(2.5)  # Wait longer than timeout + cleanup interval

            # Force a cleanup run
            await manager._cleanup_expired_locks()

            final_count = len(manager._active_locks)
            print(f"    After cleanup: {final_count} locks remaining")

            # Most locks should be cleaned up (they expired)
            assert final_count < initial_count * 0.8  # At least 20% should be cleaned up

        finally:
            await manager.stop_cleanup_task()

        print("âœ… Background cleanup under load")

    async def test_performance_benchmark(self):
        """Benchmark lock manager performance."""
        redis_client = MockRedisClient(response_delay_ms=0.5)  # Minimal latency
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        num_operations = 100

        # Benchmark lock acquisition/release cycles
        start_time = time.time()

        for i in range(num_operations):
            resource_key = f"perf_test_{i % 10}"  # 10 different resources

            async with manager.acquire_lock_context(resource_key, timeout=5) as token:
                if token:
                    # Minimal work
                    await asyncio.sleep(0.001)

        total_time = time.time() - start_time
        ops_per_second = num_operations / total_time
        avg_time_per_op = (total_time / num_operations) * 1000  # ms

        print(f"    Operations: {num_operations}")
        print(f"    Total time: {total_time:.3f}s")
        print(f"    Ops/second: {ops_per_second:.1f}")
        print(f"    Avg time per operation: {avg_time_per_op:.2f}ms")

        # Performance target: should handle > 50 ops/sec
        assert ops_per_second > 50

        # Get manager stats
        stats = manager.get_stats()
        print(f"    Success rate: {stats['performance']['success_rate']:.3f}")

        print("âœ… Performance benchmark completed")


class TestLockConfiguration:
    """Test lock configuration and validation."""

    def test_lock_config_defaults(self):
        """Test default configuration values."""
        config = LockConfig()

        assert config.default_timeout_seconds == 30
        assert config.max_timeout_seconds == 300
        assert config.retry_attempts == 3
        assert config.lock_key_prefix == "lock"
        assert config.enable_metrics is True

    def test_lock_config_validation(self):
        """Test configuration validation."""
        # Invalid timeout
        with pytest.raises(ValueError, match="default_timeout_seconds must be greater than 0"):
            LockConfig(default_timeout_seconds=0)

        # Invalid max timeout
        with pytest.raises(ValueError, match="max_timeout_seconds must be >= default_timeout_seconds"):
            LockConfig(default_timeout_seconds=60, max_timeout_seconds=30)

        # Invalid retry attempts
        with pytest.raises(ValueError, match="retry_attempts must be >= 0"):
            LockConfig(retry_attempts=-1)

    def test_create_lock_manager_convenience(self):
        """Test convenience function for creating lock managers."""
        redis_client = MockRedisClient()

        mock_l2_redis = MockL2RedisService(redis_client)
        manager = create_lock_manager(
            mock_l2_redis,
            default_timeout_seconds=45,
            retry_attempts=5,
            enable_metrics=False
        )

        assert manager.config.default_timeout_seconds == 45
        assert manager.config.retry_attempts == 5
        assert manager.config.enable_metrics is False


class TestLockFailureScenarios:
    """Test lock manager behavior under failure conditions."""

    @pytest.mark.asyncio
    async def test_redis_connection_failure(self):
        """Test behavior when Redis connection fails."""
        failing_redis = MockRedisClient(should_fail=True)
        mock_l2_redis = MockL2RedisService(failing_redis)
        manager = DistributedLockManager(mock_l2_redis)

        # All operations should fail gracefully
        token = await manager.acquire_lock("test_resource")
        assert token is None

        # Should not crash on release
        released = await manager.release_lock("test_resource", "fake_token")
        assert released is False

        # Should not crash on extend
        extended = await manager.extend_lock("test_resource", "fake_token", 30)
        assert extended is False

        print("âœ… Redis connection failure handled gracefully")

    @pytest.mark.asyncio
    async def test_lock_expiration_behavior(self):
        """Test behavior with lock expiration."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        # Acquire lock with very short timeout
        token = await manager.acquire_lock("expiring_resource", timeout=1)
        assert token is not None

        # Wait for lock to expire in Redis
        await asyncio.sleep(1.2)

        # Try to release expired lock
        released = await manager.release_lock("expiring_resource", token)
        # Should fail because lock expired in Redis
        assert released is False

        print("âœ… Lock expiration behavior validated")

    @pytest.mark.asyncio
    async def test_statistics_accuracy(self):
        """Test statistics tracking accuracy."""
        redis_client = MockRedisClient()
        mock_l2_redis = MockL2RedisService(redis_client)
        manager = DistributedLockManager(mock_l2_redis)

        initial_stats = manager.get_stats()
        assert initial_stats["performance"]["total_acquire_attempts"] == 0

        # Perform various operations
        token1 = await manager.acquire_lock("stats_test_1")
        token2 = await manager.acquire_lock("stats_test_2")
        await manager.release_lock("stats_test_1", token1)
        await manager.extend_lock("stats_test_2", token2, 60)

        # Check stats
        final_stats = manager.get_stats()
        assert final_stats["performance"]["total_acquire_attempts"] == 2
        assert final_stats["performance"]["successful_acquisitions"] == 2
        assert final_stats["performance"]["total_releases"] == 1
        assert final_stats["performance"]["total_extensions"] == 1
        assert final_stats["locks"]["active_count"] == 1

        print("âœ… Statistics tracking accuracy verified")


if __name__ == "__main__":
    print("ðŸ”„ Running DistributedLockManager Concurrency Tests...")

    async def run_tests():
        print("\n1. Testing basic lock functionality...")
        basic_suite = TestDistributedLockManager()
        basic_suite.test_lock_manager_creation()
        await basic_suite.test_basic_lock_acquire_release()
        await basic_suite.test_lock_acquisition_conflict()
        await basic_suite.test_token_based_security()
        await basic_suite.test_lock_extension()
        await basic_suite.test_context_manager()
        await basic_suite.test_context_manager_exception_handling()
        await basic_suite.test_retry_logic()

        print("\n2. Testing concurrency scenarios...")
        concurrency_suite = TestDistributedLockConcurrency()
        await concurrency_suite.test_high_concurrency_lock_contention()
        await concurrency_suite.test_multiple_resource_locking()
        await concurrency_suite.test_lock_cleanup_under_load()
        await concurrency_suite.test_performance_benchmark()

        print("\n3. Testing configuration...")
        config_suite = TestLockConfiguration()
        config_suite.test_lock_config_defaults()
        config_suite.test_lock_config_validation()
        config_suite.test_create_lock_manager_convenience()

        print("\n4. Testing failure scenarios...")
        failure_suite = TestLockFailureScenarios()
        await failure_suite.test_redis_connection_failure()
        await failure_suite.test_lock_expiration_behavior()
        await failure_suite.test_statistics_accuracy()

    # Run the tests
    asyncio.run(run_tests())

    print("\nðŸŽ¯ DistributedLockManager Concurrency Testing Complete")
    print("   âœ… Basic lock acquisition and release with token security")
    print("   âœ… High concurrency contention handling with automatic retry")
    print("   âœ… Multiple resource locking with parallel processing")
    print("   âœ… Background cleanup and expiration management")
    print("   âœ… Performance benchmarking with >50 ops/second target")
    print("   âœ… Configuration validation and convenience functions")
    print("   âœ… Failure scenario resilience and graceful degradation")
    print("   âœ… Context manager patterns for automatic resource cleanup")
